{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "한글Text분석_guide.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMGfd/UEVysuFxqNnVmc1hV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnv20/cakd3/blob/main/%ED%95%9C%EA%B8%80Text%EB%B6%84%EC%84%9D_guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GqVFxoxynTb",
        "outputId": "f04e1bb3-6cac-4392-f72a-57c6ea1b50b9"
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', my_path)\n",
        "sys.path.insert(0,my_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kddqlmCr1kPe"
      },
      "source": [
        "### 형태소 : 의미를 가지는 요소로서는 더 이상 분석할 수 없는 가장 작은 말의 단위\n",
        "### KoNLPy는 시중에 공개된 hannanum, kkma, okt, komoran, mecab 다섯개 형태소 분석기를 한꺼번에 묶어서 편리하게 사용할 수 있도록 한 패키지\n",
        "### okt\n",
        "- morphs(phrase, norm=False, stem=False)\\\n",
        "  Parse phrase to morphemes.\n",
        "- nouns(phrase)  \n",
        "- phrases(phrase)  \n",
        "- pos(phrase, norm=False, stem=False, join=False)\\\n",
        "  매개 변수:\\\n",
        "  norm -- If True, normalize tokens.\\\n",
        "  stem -- If True, stem tokens.\\\n",
        "  join -- If True, returns joined sets of morph and tag\n",
        " \n",
        "- 파싱(Parsing)\n",
        " - 일련의 문자열을 의미있는 token(어휘 분석의 단위)으로 분해하고 그것들로 이루어진 Parse tree를 만드는 과정\n",
        " - 어떤 문장을 분석하거나 문법적 관계를 해석하는 행위\n",
        " - 프로그램을  compile하는 과정에서 특정 프로그래밍 언어가 제시하는 문법을 잘 지켜서 작성하였는지 compiler가 검사하는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmHBmhc91qf6",
        "outputId": "0d218caa-8ff4-4e2d-d570-417ef97f7732"
      },
      "source": [
        "# 형태소 분석으로 문장을 단어로 분할\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "print('형태소:', okt.morphs('단독입찰보다 복수입찰의 경우'))\n",
        "print('명사:', okt.nouns('유일하게 항공기 체계 종합개발 경험을 갖고 있는 KAI는'))\n",
        "print('구문:', okt.phrases('날카로운 분석과 신뢰감 있는 진행으로'))\n",
        "print('품사:', okt.pos('이것도 되나욬ㅋㅋ'))\n",
        "print('norm옵션:', okt.pos('이것도 되나욬ㅋㅋ',norm=True))\n",
        "print('stem옵션:', okt.pos('이것도 되나욬ㅋㅋ',norm=True, stem=True))\n",
        "print('join옵션:', okt.pos('이것도 되나욬ㅋㅋ',norm=True, stem=True,join=True))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "형태소: ['단독', '입찰', '보다', '복수', '입찰', '의', '경우']\n",
            "명사: ['항공기', '체계', '종합', '개발', '경험']\n",
            "구문: ['날카로운 분석', '날카로운 분석과 신뢰감', '날카로운 분석과 신뢰감 있는 진행', '분석', '신뢰', '진행']\n",
            "품사: [('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나욬', 'Noun'), ('ㅋㅋ', 'KoreanParticle')]\n",
            "norm옵션: [('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나요', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n",
            "stem옵션: [('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되다', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n",
            "join옵션: ['이/Determiner', '것/Noun', '도/Josa', '되다/Verb', 'ㅋㅋ/KoreanParticle']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0VKtPQJ5qZ8"
      },
      "source": [
        "#### Q. 아래 문장을 적절한 Okt 옵션을 사용해서 형태소 분석 하세요.\n",
        "Okt 옵션 : morphs, nouns, phrases, normalize, pos(norm, stem, join)\n",
        "\n",
        "- '나는 오늘 방콕에 가고싶다.' (명사만 추출)\n",
        "- '나는 오늘 방콕에 갔다.' (원형만 추출)\n",
        "- '친절한 코치와 재미있는 친구들이 있는 도장에 가고 싶다.' (형태소 추출)\n",
        "- '나는 오늘도 장에 가고싶다.' (형태소/태그 추출) \n",
        "- '나는 오늘 장에 가고싶을깤ㅋㅋ?' (정규화, 원형 추출)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTjXdThP3t3E",
        "outputId": "cf7bfc0c-49a2-48c9-9a1e-194797f5680e"
      },
      "source": [
        "print('명사만 추출:',okt.nouns('나는 오늘 방콕에 가고싶다.'))\n",
        "print('원형만 추출:',okt.pos('나는 오늘 방콕에 갔다.',stem=True))\n",
        "print('형태소 추출', okt.morphs('친절한 코치와 재미있는 친구들이 있는 도장에 가고싶다.'))\n",
        "print('형태소/태그 추출:',okt.pos('나는 오늘도 장에 가고싶다.',stem=True,join=True))\n",
        "print('정규화, 원형 추출',okt.pos('나는 오늘 장에 가고싶을깤ㅋㅋ?',norm=True,stem=True))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "명사만 추출: ['나', '오늘', '방콕']\n",
            "원형만 추출: [('나', 'Noun'), ('는', 'Josa'), ('오늘', 'Noun'), ('방콕', 'Noun'), ('에', 'Josa'), ('가다', 'Verb'), ('.', 'Punctuation')]\n",
            "형태소 추출 ['친절한', '코치', '와', '재미있는', '친구', '들', '이', '있는', '도장', '에', '가고싶다', '.']\n",
            "형태소/태그 추출: ['나/Noun', '는/Josa', '오늘/Noun', '도/Josa', '장/Noun', '에/Josa', '가다/Verb', './Punctuation']\n",
            "정규화, 원형 추출 [('나', 'Noun'), ('는', 'Josa'), ('오늘', 'Noun'), ('장', 'Noun'), ('에', 'Josa'), ('가다', 'Verb'), ('ㅋㅋ', 'KoreanParticle'), ('?', 'Punctuation')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNml_Zny9Qt7"
      },
      "source": [
        "[과제] 한글 형태소 분석을 위한 text를 크롤링한 후 원하는 형태로 다양하게 형태소 분석 하세요(20분 후 발표)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEXOITKX9ph7",
        "outputId": "9438857d-cfa6-4b54-b612-e2f1988468be"
      },
      "source": [
        "import re\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "text = \"\"\"김웅 국민의힘 의원이 고위공직자범죄수사처(공수처)의 압수수색 영장을 취소해 달라며 신청한 준항고 사건을 담당할 재판부가 정해졌다.\n",
        "13일 서울중앙지방법원은 형사31단독(김찬년 판사) 재판부에 김 의원의 준항고 사건을 배당했다고 밝혔다.\n",
        "준항고는 사법기관의 처분에 불복해 법원에 이의를 제기하는 절차다. 법원이 영장 취소 결정을 내리면 공수처는 영장을 재발부받아야 한다.\n",
        "김웅 의원 측은 \"공수처의 압수수색 영장 집행 과정에서 위법성이 있기 때문에 영장을 취소해달라는 취지의 준항고장을 접수했다\"고 밝힌 바 있다.\n",
        "김 의원 측은 공수처가 김 의원과 변호사의 입회 전에 일부 범죄사실만 언급한 채 영장을 집행하고, 압수물 대상에 적시되지 않은 보좌관과 비서관의 \n",
        "PC 및 서류를 조사하고 PC 자료 추출 과정에서도 혐의와 관계가 없는‘오수’등의 검색어로 검색했다는 점을 문제 삼고 있다.\"\"\"\n",
        "\n",
        "text = re.sub('[0-9]+','',text)\n",
        "text = re.sub('[A-Za-z]+','',text)\n",
        "text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ·!』\\\\‘’|\\(\\)\\[\\]\\<\\>`\\'…》]', '', text)\n",
        "print(text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "김웅 국민의힘 의원이 고위공직자범죄수사처공수처의 압수수색 영장을 취소해 달라며 신청한 준항고 사건을 담당할 재판부가 정해졌다\n",
            "일 서울중앙지방법원은 형사단독김찬년 판사 재판부에 김 의원의 준항고 사건을 배당했다고 밝혔다\n",
            "준항고는 사법기관의 처분에 불복해 법원에 이의를 제기하는 절차다 법원이 영장 취소 결정을 내리면 공수처는 영장을 재발부받아야 한다\n",
            "김웅 의원 측은 공수처의 압수수색 영장 집행 과정에서 위법성이 있기 때문에 영장을 취소해달라는 취지의 준항고장을 접수했다고 밝힌 바 있다\n",
            "김 의원 측은 공수처가 김 의원과 변호사의 입회 전에 일부 범죄사실만 언급한 채 영장을 집행하고 압수물 대상에 적시되지 않은 보좌관과 비서관의 \n",
            " 및 서류를 조사하고  자료 추출 과정에서도 혐의와 관계가 없는오수등의 검색어로 검색했다는 점을 문제 삼고 있다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5WM5ln6M4jh",
        "outputId": "77fd7ec2-ff24-4525-fc5b-42403ee797dc"
      },
      "source": [
        "morph = okt.pos(text)\n",
        "noun_list = []\n",
        "for word, tag in morph:\n",
        "  if tag == 'Noun':\n",
        "    noun_list.append(word)\n",
        "print(morph)\n",
        "print(noun_list)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('김웅', 'Noun'), ('국민', 'Noun'), ('의', 'Josa'), ('힘', 'Noun'), ('의원', 'Noun'), ('이', 'Josa'), ('고위', 'Noun'), ('공직자', 'Noun'), ('범죄수사', 'Noun'), ('처', 'Noun'), ('공', 'Modifier'), ('수', 'Modifier'), ('처', 'Noun'), ('의', 'Josa'), ('압수수색', 'Noun'), ('영장', 'Noun'), ('을', 'Josa'), ('취소', 'Noun'), ('해', 'Verb'), ('달라', 'Noun'), ('며', 'Josa'), ('신청', 'Noun'), ('한', 'Josa'), ('준', 'Noun'), ('항고', 'Noun'), ('사건', 'Noun'), ('을', 'Josa'), ('담당', 'Noun'), ('할', 'Verb'), ('재판', 'Noun'), ('부가', 'Noun'), ('정해졌다', 'Verb'), ('\\n', 'Foreign'), ('일', 'Noun'), ('서', 'Modifier'), ('울', 'Modifier'), ('중앙', 'Noun'), ('지방법원', 'Noun'), ('은', 'Josa'), ('형사', 'Noun'), ('단독', 'Noun'), ('김찬', 'Noun'), ('년', 'Noun'), ('판사', 'Noun'), ('재판', 'Noun'), ('부', 'Noun'), ('에', 'Josa'), ('김', 'Noun'), ('의원', 'Noun'), ('의', 'Josa'), ('준', 'Noun'), ('항고', 'Noun'), ('사건', 'Noun'), ('을', 'Josa'), ('배당', 'Noun'), ('했다고', 'Verb'), ('밝혔다', 'Verb'), ('\\n', 'Foreign'), ('준', 'Noun'), ('항고', 'Noun'), ('는', 'Josa'), ('사법', 'Noun'), ('기관', 'Noun'), ('의', 'Josa'), ('처분', 'Noun'), ('에', 'Josa'), ('불복', 'Noun'), ('해', 'Verb'), ('법원', 'Noun'), ('에', 'Josa'), ('이의', 'Noun'), ('를', 'Josa'), ('제기', 'Noun'), ('하는', 'Verb'), ('절차', 'Noun'), ('다', 'Josa'), ('법원', 'Noun'), ('이', 'Josa'), ('영장', 'Noun'), ('취소', 'Noun'), ('결정', 'Noun'), ('을', 'Josa'), ('내리면', 'Verb'), ('공', 'Modifier'), ('수', 'Modifier'), ('처', 'Noun'), ('는', 'Josa'), ('영장', 'Noun'), ('을', 'Josa'), ('재발', 'Noun'), ('부', 'Noun'), ('받아야', 'Verb'), ('한다', 'Verb'), ('\\n', 'Foreign'), ('김웅', 'Noun'), ('의원', 'Noun'), ('측은', 'Noun'), ('공', 'Modifier'), ('수', 'Modifier'), ('처', 'Noun'), ('의', 'Josa'), ('압수수색', 'Noun'), ('영장', 'Noun'), ('집행', 'Noun'), ('과정', 'Noun'), ('에서', 'Josa'), ('위법성', 'Noun'), ('이', 'Josa'), ('있기', 'Adjective'), ('때문', 'Noun'), ('에', 'Josa'), ('영장', 'Noun'), ('을', 'Josa'), ('취소', 'Noun'), ('해달라는', 'Verb'), ('취지', 'Noun'), ('의', 'Josa'), ('준', 'Noun'), ('항고', 'Noun'), ('장', 'Suffix'), ('을', 'Josa'), ('접수', 'Noun'), ('했다고', 'Verb'), ('밝힌', 'Verb'), ('바', 'Noun'), ('있다', 'Adjective'), ('\\n', 'Foreign'), ('김', 'Noun'), ('의원', 'Noun'), ('측은', 'Noun'), ('공수', 'Noun'), ('처가', 'Noun'), ('김', 'Noun'), ('의원', 'Noun'), ('과', 'Josa'), ('변호사', 'Noun'), ('의', 'Josa'), ('입회', 'Noun'), ('전', 'Noun'), ('에', 'Josa'), ('일부', 'Noun'), ('범죄', 'Noun'), ('사실', 'Noun'), ('만', 'Josa'), ('언급', 'Noun'), ('한', 'Josa'), ('채', 'Noun'), ('영장', 'Noun'), ('을', 'Josa'), ('집행', 'Noun'), ('하고', 'Josa'), ('압수', 'Noun'), ('물', 'Noun'), ('대상', 'Noun'), ('에', 'Josa'), ('적시되', 'Verb'), ('지', 'Verb'), ('않은', 'Verb'), ('보좌', 'Noun'), ('관', 'Noun'), ('과', 'Josa'), ('비서', 'Noun'), ('관', 'Noun'), ('의', 'Josa'), ('및', 'Noun'), ('서류', 'Noun'), ('를', 'Josa'), ('조사', 'Noun'), ('하고', 'Josa'), ('자료', 'Noun'), ('추출', 'Noun'), ('과정', 'Noun'), ('에서도', 'Josa'), ('혐의', 'Noun'), ('와', 'Josa'), ('관계', 'Noun'), ('가', 'Josa'), ('없는오수', 'Adjective'), ('등', 'Noun'), ('의', 'Josa'), ('검색어', 'Noun'), ('로', 'Josa'), ('검색', 'Noun'), ('했다는', 'Verb'), ('점', 'Noun'), ('을', 'Josa'), ('문제', 'Noun'), ('삼고', 'Noun'), ('있다', 'Adjective')]\n",
            "['김웅', '국민', '힘', '의원', '고위', '공직자', '범죄수사', '처', '처', '압수수색', '영장', '취소', '달라', '신청', '준', '항고', '사건', '담당', '재판', '부가', '일', '중앙', '지방법원', '형사', '단독', '김찬', '년', '판사', '재판', '부', '김', '의원', '준', '항고', '사건', '배당', '준', '항고', '사법', '기관', '처분', '불복', '법원', '이의', '제기', '절차', '법원', '영장', '취소', '결정', '처', '영장', '재발', '부', '김웅', '의원', '측은', '처', '압수수색', '영장', '집행', '과정', '위법성', '때문', '영장', '취소', '취지', '준', '항고', '접수', '바', '김', '의원', '측은', '공수', '처가', '김', '의원', '변호사', '입회', '전', '일부', '범죄', '사실', '언급', '채', '영장', '집행', '압수', '물', '대상', '보좌', '관', '비서', '관', '및', '서류', '조사', '자료', '추출', '과정', '혐의', '관계', '등', '검색어', '검색', '점', '문제', '삼고']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgWLcGqnP4Ix",
        "outputId": "e95ed02c-26fb-4d62-a257-7bdde30fcb02"
      },
      "source": [
        "import codecs\n",
        "from bs4 import BeautifulSoup\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "fp = codecs.open('/content/drive/MyDrive/cakd3_colab/textmining/dataset/BEXX0003.txt','r',encoding='utf-16')\n",
        "soup = BeautifulSoup(fp,'html.parser')\n",
        "body = soup.select_one('body > text')\n",
        "text = body.getText()\n",
        "\n",
        "okt = Okt()\n",
        "word_dic = {}\n",
        "lines = text.split('\\n')\n",
        "for line in lines:\n",
        "  malist = okt.pos(line)\n",
        "  for word in malist:\n",
        "    if word[1] == 'Noun':\n",
        "      if not (word[0] in word_dic):\n",
        "        word_dic[word[0]] = 0\n",
        "      word_dic[word[0]] += 1 # 카운트 하기\n",
        "\n",
        "keys = sorted(word_dic.items(), key=lambda x:x[1], reverse=True)\n",
        "for word, count in keys[:50]:\n",
        "  print('{0}({1}) '.format(word,count), end='')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "것(644) 그(554) 말(485) 안(304) 소리(196) 길(194) 용이(193) 눈(188) 놈(180) 내(174) 사람(167) 봉(165) 치수(160) 평산(160) 얼굴(156) 거(152) 네(151) 일(149) 이(148) 못(147) 댁(141) 생각(141) 때(139) 강청댁(137) 수(134) 서방(131) 집(131) 나(122) 더(120) 서희(119) 머(116) 어디(112) 마을(111) 최(110) 년(109) 김(99) 칠성(97) 구천이(96) 니(96) 뒤(91) 제(90) 날(90) 아이(88) 하나(84) 녀(83) 두(83) 참판(82) 월(82) 손(81) 임(79) "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzUHJYsqU8KA"
      },
      "source": [
        "### 문장을 벡터로 변환하기\n",
        "- 단계 \n",
        " - 코퍼스 생성 : 데이터 내려받기 - XML을 일반 텍스트로 변환 - 형태소 분석, 단어로 구분\n",
        " - 코퍼스를 이용하여 Word2Vec로 모델 생성하며 단어를 벡터로 변환하고 모델 저장\\\n",
        "   매개변수 : sg 알고리즘 선택(1=Skip-gram, 0=CBOW), size (벡터의 차원 설정), window (학습할 단어를 연관시킬 앞뒤의 단어 수)\n",
        " - 모델을 읽어 들여 계산에 사용\n",
        "- Word2Vec : 구글의 토머스 미코로프가 만든 방법으로 딥러닝 기술을 사용하여 단어를 벡터로 만드는 방법으로 대량의 문장을 기반으로 학습하고 단어를 벡터로 변환\n",
        " - 단어는 그 주변의 단어들과 관계가 있다.\n",
        " - 특정 단어의 유의어, 반의어를 추출할 수 있다.\n",
        " - 단어를 선형으로 나타낼 수 있다.\n",
        " - 자연 언어 처리에 활용할 수 있다.\n",
        " - 추천 분류 시스템에 다양하게 사용될 수 있다.\n",
        "- Word2Vec 알고리즘\n",
        " - Skip-gram\n",
        " - CBOW \n",
        " \n",
        "※ 코퍼스(Corpus) : 모델을 만들기 위한 대량의 띄어쓰기로 구분한 데이터를 포함. 컴퓨터로 검색이 가능한 대량의 언어 데이터\\\n",
        "※ Word2Vec는 띄어쓰기로 구분된 단어를 학습시키는 이론. 형태소 분석을 사용해 단어들을 정규화해서 추출하고 이를 기반으로 띄어쓰기로 구분한 데이터를 준비 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOTOyXfFRKb3"
      },
      "source": [
        "!pip install --target=$my_path gensim\n",
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTrK29V-YQQv",
        "outputId": "ae82214f-c3d0-419c-f0cf-5a7510d63cbc"
      },
      "source": [
        "import codecs\n",
        "from bs4 import BeautifulSoup\n",
        "from konlpy.tag import Okt\n",
        "from gensim.models import word2vec\n",
        "# utf-16 인코딩으로 파일을 열고 글자를 출력하기\n",
        "fp = codecs.open(\"/content/drive/MyDrive/cakd3_colab/textmining/dataset/BEXX0003.txt\", \"r\", encoding=\"utf-16\")\n",
        "soup = BeautifulSoup(fp, \"html.parser\")\n",
        "body = soup.select_one(\"body > text\")\n",
        "text = body.getText()\n",
        "\n",
        "okt = Okt()\n",
        "results = []\n",
        "lines = text.split(\"\\n\")\n",
        "for line in lines:\n",
        "    malist = okt.pos(line, norm=True, stem=True)\n",
        "    r = []\n",
        "    for word in malist:        \n",
        "        if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
        "            r.append(word[0])\n",
        "          \n",
        "    rl = (\" \".join(r)).strip()\n",
        "    results.append(rl)\n",
        "\n",
        "wakati_file = '/content/drive/MyDrive/cakd3_colab/textmining/dataset/toji.wakati'\n",
        "with open(wakati_file, 'w', encoding='utf-8') as fp:\n",
        "    fp.write(\"\\n\".join(results))\n",
        "# Word2Vec 모델 만들기 \n",
        "data = word2vec.LineSentence(wakati_file)\n",
        "model = word2vec.Word2Vec(data, vector_size=200, window=10, hs=1, min_count=2, sg=1)\n",
        "model.save(\"/content/drive/MyDrive/cakd3_colab/textmining/dataset/toji.model\")\n",
        "print(\"ok\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2sXttwFZp1W"
      },
      "source": [
        "model = word2vec.Word2Vec.load(\"/content/drive/MyDrive/cakd3_colab/textmining/dataset/toji.model\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLBLhEbOc0zF",
        "outputId": "39b4ffdc-9064-48ad-b27e-f0f87bc1ea0d"
      },
      "source": [
        "model.wv.most_similar(positive=['집'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('구석', 0.7528995275497437),\n",
              " ('제', 0.7428428530693054),\n",
              " ('그까짓', 0.735120415687561),\n",
              " ('만나다', 0.7341201901435852),\n",
              " ('이지마', 0.7328251004219055),\n",
              " ('소나', 0.7271293997764587),\n",
              " ('돌아가다', 0.7241018414497375),\n",
              " ('돌아오다', 0.719454288482666),\n",
              " ('가끔', 0.7183434963226318),\n",
              " ('앙님', 0.7171241641044617)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6PxIFK0dflT"
      },
      "source": [
        "[과제] 뉴스 기사를 Word2Vec을 이용해서 모델을 만들고 성능을 테스트 해보세요."
      ]
    }
  ]
}